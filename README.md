# XR-NPE
## Multi-Precision Quantization for Vision and Sensor Fusion Models

This repository provides Python implementations of **multi-precision quantization** for various computer vision and sensor fusion workloads.  
It has three workloads:  
- [`Gaze-LLE`](./Gaze-LLE) â€“ Eye gaze extraction
- [`ResNet`](./Resnet) â€“ Image classification
- [`UL-VIO`](./UL-VIO) â€“ Visual-Inertial Odometry 

The code supports the following quantization formats:
- **FP4**  
- **FP8**  
- **Posit4** (Posit(4,1))  
- **Posit8** (Posit(8,0))  
- **BF16**
- **Mixed-Precision**

This  facilitates  researchers and practitioners to explore the **trade-offs across accuracy, latency, and resource usage**.

---

## ğŸ“‚ Repository Structure
```text
multi-precision-quantization/
â”‚
â”œâ”€â”€ Gaze-LLE/   # Eye gaze estimation quantization â€” BF16, FP4, FP8, Posit4, Posit8
â”‚
â”œâ”€â”€ Resnet/     # ResNet image classification quantization â€” BF16, FP4, FP8, Posit8
â”‚
â”œâ”€â”€ UL-VIO/     # Visualâ€“Inertial Odometry quantization â€” BF16+INT8, FP4, FP8, Mixed Precision (Posit8+FP4), Posit4/8/16
â”‚
â””â”€â”€ README.md   # Generic README
```
---

## âš™ï¸ Installation

Clone the repository:
```bash
git clone https://github.com/XXXXXXXXXXXXXXXX/XR-NPE.git
cd XR-NPE
pip install -r requirements.txt
pip install -r requirements_extra.txt  #for some additional library might be used
```
## Model Output Previews
<table>
<tr>
<td align="center"><img src="images/fp32.png" width="200"/><br><b>Gaze-LLE</b></td>
<td align="center"><img src="images/resnet18_final.jpg" width="200"/><br><b>ResNet</b></td>
<td align="center"><img src="images/ul_vio.png" width="200"/><br><b>UL-VIO</b></td>
</tr>
</table>

## ğŸ”— References
- [Gaze-LLE](https://github.com/fkryan/gazelle)
- [ResNet](https://github.com/JayPatwardhan/ResNet-PyTorch)
- [UL-VIO](https://github.com/jp4327/ulvio)
